\section{Methods}
\label{sec:methods}

\input{Sections/dataset.tex}
\input{Sections/preprocessing.tex}

\subsection{3D-CNN architecture}
The proposed CNN consist of a 3D multistream architecture that follows the analysis and synthesis path of the 3D U-Net \cite{cciccek20163d}. Our implementation follows the one described by Anneke et al. in 2018  \cite{anneke}. The input of each stream is the post-processed ROI with a resolution of $168^3$ for one of three MRI series (axial, sagittal, and coronal). During the analysis phase, a group of two convolutional layers and one max pool layer is repeated three times. The second convolutional layer in each group doubles the number of filters.  In the synthesis phase, a similar set of two convolutional layers and one deconvolution is applied three times. We modified the original network by implementing batch normalization \cite{ioffe2015batch} and Dropout of 20\%  \cite{hinton2012improving} after each convolution in the synthesis path.\\

We also cut down on the number of filters from $192$ to $28$ in the largest convolutional layer (after the first concatenation) reducing the number of parameters from to 995k to 663k. These changes cut the training time in half and improved the generalization of the  model. Figure \ref{fig:fig_3} shows the proposed model; all convolutional layers use a filter size of $3 \times 3 \times 3$ and rectified linear unit (ReLu) as the activation function; except the last layer which uses a filter size of $1 \times 1 \times 1$ and Sigmoid as the activation function to match the resolution of the input MRI series.
% fig:fig_3

\subsection{Training}
\label{subsec:training}
The selected optimization algorithm is Stochastic Gradient Descent (SGD) with a learning rate $\alpha = 0.001$, momentum of 0.9 and decay of $10^{-6}$. The training is performed for 1000 epochs with an early stop mechanism if the loss function is not improved by at least $\delta = 0.001$ after 70 iterations. The Loss function used is the negative Dice Similarity Coefficient (DSC) \cite{dice1945measures}:  
\begin{equation}
\text{Loss} = - \frac{2 \sum_{i=1}^{N}p_it_i}{\sum_{i=1}^{N}p_i^2 + \sum_{i=1}^{N}t_i^2 + \varepsilon} 
\label{eq:dsc}
\end{equation}
where N is the total number of voxels in the image, $p_i$ the voxel values for the prediction of the network, $t_i$ the true voxel values of the prostate or PZ masks, and $\varepsilon = 1$ for all the models.

In order to compare the robustness of the models with respect to changes in MRI vendor machines,  a distinct model was trained for each dataset: GE (n=220), Siemens (n=330), and combined model (n=550). Each dataset was split into 90\% for training and 10\% for validation. Data augmentation was performed on the fly by flipping the images in the sagittal axis and blurring them using 3D Gaussian blur randomly with $0 \leq \sigma \leq 3$. Each data augmentation method is applied with a random chance of $1/2$.  
A total number of six models are compared, three for the prostate been trained with each dataset and three more for the PZ. 

The training was performed on a desktop computer with an Intel Xeon(R) E5-2609 CPU and a GeForce GTX 1080 Ti NVIDIA GPU. The system is implemented using Keras \cite{chollet2015} and Tensor Flow \cite{tensorflow2015-whitepaper} python libraries. The average training time for each model, independently if its for the prostate or the PZ, is $\sim 7.5$ hours, the overall training time for the six models is about two days.

\subsection{Postprocessing}
The CNN outputs a 3D volume of the same size of the ROI, in our case $168^3$, and each voxel gets the probability of belonging to the area of interest (prostate or PZ) versus the background. From this volume a binary mask is obtained with a threshold value of 0.5. After that, the largest connected volume is selected. Finally, the 3D DSC for the contour of interest in the resampled image and in the original MRI series resolution is computed. The prediction of the PZ contour is intersected with the prostate, restricting it to the prostate volume.