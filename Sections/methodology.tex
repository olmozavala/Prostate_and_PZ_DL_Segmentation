\section{Methods}
\label{sec:methods}

\input{Sections/dataset.tex}
\input{Sections/preprocessing.tex}

\subsection{3D-CNN architecture}
The proposed CNN consist of a 3D multistream architecture that follows the analysis and synthesis path of the 3D U-Net \cite{cciccek20163d}. Our implementation follows the one proposed by Anneke et al. in 2018  \cite{anneke}. The input of each stream is the post-processed ROI with a resolution of $168^3$ for one of three MRI series (axial, sagittal, and coronal). During the analysis phase, a combination of two convolutional layers and one max pool layer is grouped and repeated three times. The second convolutional layer in each set doubles the number of channels.  In the synthesis phase, a similar set of two convolutional layers and one deconvolution is applied three times. we modified the original network by implementing batch normalization \cite{ioffe2015batch} after each deconvolution and Dropout of 20\% \cite{hinton2012improving}.\\
We also cut down on the number of filters from $192$ to $28$ in the largest convolutional layer (after the first concatenation) reducing the number of parameters from to 995k to 663k in this layer. These changes reduced the training time in half as well the generalization of the  model. Figure \ref{fig:fig_3} shows the utilized model, all convolutional layers use a filter size of $3 \times 3 \times 3$ and rectified linear unit (ReLu) as the activation function; with the exception of the last layer which uses a filter size of $1 \times 1 \times 1$ and Sigmoid as the activation function to match the resolution of the input MRI series.
%\begin{figure*}[h]
%    \centering
%    \includegraphics[totalheight=.282\textheight]{figures/Figure3.eps}
%    \caption{Multistream 3D convolutional network architecture. The input of the network are three $168^3$ volumes from the MRI planes: axial, sagittal, and coronal. }
%    \label{fig:fig_3}
%\end{figure*}
Finally, we demonstrate that even though the CNN was trained and tested on T2-w MRIs with sizes $168^3$, the final model is not restricted to that input size and could be used with different resolutions, as long as the field of view of the isotropic input volume being used is similar to the training data. 

\subsection{Training}
\label{subsec:training}
The selected optimization algorithm is Stochastic Gradient Descent (SGD) with a learning rate $\alpha = 0.01$, momentum of 0.9 and decay of $10^{-6}$. The training is performed for 1000 epochs with an early stop mechanism if the loss function is not improved by at least $\delta = 0.001$ after 70 iterations. 

The Loss function used for the training is the negative Dice Similarity Coefficient (DSC)(Dice, L. R. Measures of the Amount of Ecologic Association between Species. Ecology 26, 297-302, doi:Doi 10.2307/1932409 (1945)):  
\begin{equation}
\text{Loss} = - \frac{2 \sum_{i=1}^{N}p_it_i}{\sum_{i=1}^{N}p_i^2 + \sum_{i=1}^{N}t_i^2 + \varepsilon} 
\label{eq:dsc}
\end{equation}
%where N is the total number of voxels in the image, when training for prostate segmenation,
%and the number of voxels \textbf{inside} the prostate, when training for the PZ. The segmentation
%of the PZ assumes that we already know where the prostate is, so we do not take into
%account anything outside the prostate for the loss function. 
where N is the total number of voxels in the image, $p_i$ the voxel values for the prediction of the network, and $t_i$ the true voxel values of the prostate or PZ masks.

In order to compare the robustness of the models with respect to changes in MRI vendor machines,  a distinct model was trained for each dataset: GE (n=220), Siemens (n=330), combined model (n=550). Each dataset was split into 90\% for training and 10\% for validation. Data augmentation was performed on the fly by flipping the axail images in the sagittal axis and blurring them using 3D Gaussian blur up to $\sigma = 3$. Each data augmentation method is applied with a random chance of $1/2$.  
A total number of 6 models were trained from the combination of three datasets, and training for the segmentation of the prostate or the PZ. 

\subsection{Postprocessing}
The CNN outputs a 3D volume of the same size of the ROI, in our case $168^3$. From this cube, a binary mask is obtained by thresholding it with a value of 0.5. After that, we select the largest connected volume and remove all others. Finally, we compute the 3D DSC for the contour of interest in the resampled image and in the original MRI resolution. Additionally, the prediction of the PZ contour is intersected with the prostate, restricting it to the prostate volume.

